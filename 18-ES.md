## 概述

ES 官方文档，根据版本查询对应API，本文档不一定符合当前版本

```http
https://www.elastic.co/guide/en/elasticsearch/reference/index.html
```

优点：

* 横向可扩展，扩大集群容易。
* 分片机制提供更好的分布性。
* 高可用，提供复制机制。
* 使用简单。

全文搜索是指通过扫描文章中的每一个词，对每个词建立一个索引，指明该词在文章中出现的次数和位置。

倒排索引：对文档或者文档集合中的单词建立索引，用来储存这些单词在文档或者一组文档中出现的频度、位置。

术语：

* 索引词：一个能够被索引的精确词。
* 文本：一段普通的非结构化文字，通常文本会被分析成一个个索引词。
* 分析：将文本转换为索引词的过程，分析结果依赖于分词器。
* 集群：集群由一个或多个节点组成，对外提供服务。在所有节点中，一个集群由一个唯一的名称，默认为 ElasticSearch，不同的集群应当使用不同的名称，节点是通过集群名称加入集群的。
* 节点：一个逻辑上独立的服务，节点也有唯一的名字，在网络中集群通过名字来管理和通信，当网络中没有集群运行时，只要启动任何一个节点，就会生成一个只有一个节点的集群。
* 路由：储存文档时，会储存在唯一的主分片中，具体哪个分片时通过散列值进行选择，默认情况下，散列值由文档ID生成，如果文档存在一个父文档，则由父文档ID生成。
* 分片：单个Lucene(全文搜索引擎工具包)实例，文档储存在分片中，分片分配在集群的节点，当集群扩容或缩小时，ElasticSearch 将自动在节点间迁移分片，以使集群保持平衡。
* 主分片：储存文档时，系统会首先储存在主分片中，然后会复制到不同的副本，默认情况一个索引有5个分片，分片一旦建立，数量就不能修改。
* 副本分片：每个分片有零个或多个副本，副本是主分片的复制，有两个目的：

  1. 增加高可用性，允许水平分割扩展数据：当主分片失败时，可用从副本中选择一个作为主分片。
  2. 提高性能，允许分配和并行操作提高吞吐量：可以通过主分片或者副本分片进行查询。默认情况下，一个主分片配有一个副本，但副本的数量可以在后面动态地配置增加。副本分片必须部署在不同的节点，不能部署在和主分片相同的节点。

  默认情况下，每个索引分配5个分片和一个副本，意味着集群节点至少要有两个，将拥有5个主分片、5个副本分片。
* 索引：名词表示 具有相同结构的文档集合，对应关系型数据库的 Database，动词表示把文档储存到索引(名词)中，对应关系型数据库的 Insert 操作。
* 类型：在索引中可以定义一个或多个类型，类型是索引的逻辑分区，对应关系型数据库的 Table。
* 文档：储存在 ElasticSearch 中的一个JSON格式的字符串，代表一行数据，对应关系型数据库的 Row。每个储存在索引中的文档都有一个类型和一个ID，每个文档都是一个JSON对象，储存了零个或多个字段，原始的JSON文档被储存在 _source 的字段中，当搜索文档时默认返回的就是这个字段。
* 映射：映射像关系数据库中的表结构，每个类型都有一个映射。
* 字段：文档中包含零个或多个字段，对应关系型数据库的 Column。
* 来源字段：默认情况下，原文档储存在 _source 字段。
* 主键：如果存库时没有，会自动生成一个，文档的 index/type/id 必须唯一。

分布式特性：

* 将文档分区到不同的容器或者分片(shards)中，它们可以存在于一个或多个节点中。
* 将分片均匀的分配到各个节点，对索引和搜索做负载均衡。
* 冗余每一个分片，防止硬件故障造成的数据丢失。
* 将集群中任意一个节点上的请求路由到相应数据所在的节点。
* 无论是增加节点，还是移除节点，分片都可以做到无缝的扩展和迁移。

## 常用配置

```yaml
# 集群名称，节点通过该值加入集群
cluster.name
# 节点名称
node.name
# 机架名称
node.rack
# 索引储存位置
path.data
# 日志储存位置
path.logs
# 内存分配模式，为true时先获取配置大小内存，再加入集群，并且禁止内存和磁盘交换
bootstrap.mlockall
# 绑定ip地址，默认127.0.0.1
network.host
# http端口
http.port
```

## 数据

### curl

格式：`curl <options> <url>`

options：

* -o：`-o <file-name>` , 将请求保存为文件。
* -O：用原文件名保存。
* -C -：断点继续下载。
* -i：打印响应头。
* -b：传递cookie。
* -H：指定header，例如`-H 'content-type: application/json'`
* -X：指定请求方法，例如`-X POST`
* -d：指定请求数据。
* -F：向服务器上传二进制文件，例如`-F 'file=@photo.png;type=image/png'`
* -k：跳过ssl检测。
* -L：跟随重定向。
* -s：不输出错误信息和进度信息。
* -S：只输出错误信息。
* -u：设置用户名密码。

### API约定

* 多索引参数：

  1. `test1,test2,test3` : 表示同时搜索 test1，test2，test3 三个索引中的数据。
  2. `_all` : 内部关键字，表示全部索引。
  3. `+test*,-test3` : 表示查询所有 test 开头的索引，排除 test3。
  4. `ignore_unavailable` : 当索引不存在或者关闭的时候，是否忽略这些索引，不会抛出error。
  5. `allow_no_indices` : 当使用通配符查询所有索引的时候，当有索引不存在的时候是否返回查询失败。
  6. `expand_wildcards` : open 表示只支持开启状态的索引，close 表示只支持关闭状态的索引，none 表示 不可用，all 表示同时支持 open 和 close 索引。
  7. `<static_name{date_math_expr{date_format|time_zone}}>` : 按日期筛选

     ```bash
     # static_name ：索引的名称
     # date_math_expr：动态日期计算表达式
     # date_format ：日期格式
     # time_zone：时区，默认为 UTC
     curl -XGET 'localhost:9200/<logstash-{now%2Fd-2d}>/_search' {
       "query" : {
           ...
       }
     }
     # | 被转义为 %2F
     ```
* 通用参数

  1. `?pretty=true`,`?format=yaml` : 返回格式化后的JSON数据或者YAML数据。
  2. `+1h` 增加一个小时 `-1d` 减少一个小时 `/d` 上一个小时，所支持的时间单位为：y（年）、M（月）、w（周）、d（日）、h（小时）、m（分钟）、
     s（秒），表达式设定的日期为 now 或者日期字符串加||。

     ```bash
     # 当前时间加一小时，以毫秒为单位。
     now+1h
     # 当前时间加一小时和一分钟，以毫秒为单位。
     now+1h+1m
     # 当前时间加一小时，四舍五入到最近的一天。
     now+1h/d
     # 2015-01-01 加一个月，向下舍入到最接近的一天。
     2015-01-01||+1M/d
     ```
  3. 所有的返回值可以通过 filter_path 来减少返回值的内容，多个值可以用逗号分开，也可以使用 `*`(匹配任何部分字段的名称) 和 `**`(匹配不确定名称的字段) 通配符。

     ```bash
      curl -XGET 'localhost:9200/_nodes/stats?filter_path=nodes.*.ho*'
      {
        "nodes" : {
           "lvJHed8uQQu4brS-SXKsNA" : {
              "host" : "portable"
           }
        }
      }
     ```

### 集群

* 关闭分片分配：当关闭一个节点的时候，会立即试图复制这个节点的数据到集群的其他节点，将导致大量的 IO 请求，可以在关闭该节点时设置参数来避免。

  ```bash
  PUT /_cluster/settings
  {
    "transient": {
       "cluster.routing.allocation.enable": "none"
    }
  }
  ```
* 重新分配

  ```bash
  PUT /_cluster/settings
  {
    "transient": {
      "cluster.routing.allocation.enable": "all"
    }
  }
  ```
* 刷新数据到Lucene持久化保存

  ```bash
  POST /_flush
  ```
* 查看集群状态，当节点加入集群后，它首先恢复存储在本地的主分片数据，当每个节点都恢复完成后，集群的状态将会变成黄色，表示所有主分片已经被找到，但是并不是所有
  的副本分片都恢复。

  ```bash
  GET _cat/health
  ```

升级节点：

1. 关闭分片分配。
2. 刷新数据到Lucene持久化保存。
3. 升级节点。
4. 重新分配。

### 索引

* 创建索引

```bash
PUT http://127.0.0.1:9200/secisland/
{
  "settings" : {
       "index" : {
         "number_of_shards" : 3,
         "number_of_replicas" : 2
       }
  }
}
# 或者简写为
{
   "settings": {
     "number_of_shards": 3,
     "number_of_replicas": 2
   }
}
```

* 打开关闭索引，关闭的索引只能显示索引元数据信息，不能够进行读写操作。

```bash
POST 127.0.0.1:9200/secisland/_close
```

* 映射管理，默认情况下会自动判断类型，也可以主动设置

```bash
PUT <索引>/_mapping/<文档> 
{
   "properties": {
     "name": {
       "type": "string",
       "index": "not_analyzed"
     },
      "text": { 
       "type": "string",
       "analyzer": "standard"
     }
   }
}
```

* 新增索引别名,一个别名可以关联多个索引

```bash
POST http://localhost:9200/_aliases
{
 "actions" : [
     { "remove" : { "index" : "test1", "alias" : "alias1" } },
     { "add" : { "index" : "test1", "alias" : "alias2" } }
 ] 
}
```

* 测试分析器

```bash
GET localhost:9200/_analyze
{
   "analyzer" : "standard",
   "text" : "this is a test"
}
```

索引分析的过程：

1. 字符过滤器：将字符串过滤，例如去除HTML标记 或者转换 "&" 为 "and"。
2. 分词器：进行分词。
3. 标记过滤器：每个词都通过标记过滤器处理，可以修改词、去掉词、增加词等。

测试分词器：

```bash
GET localhost:9200/_analyze
{
  "analyzer" : "standard",
  "text" : "this is a test"
}
```

自定义分词器：

GET localhost:9200/_analyze
{
"tokenizer" : "keyword",
"token_filters" : ["lowercase"],
// 分词结果会去掉html标签
"char_filters" : ["html_strip"],
"text" : "this is a <b>test</b>"
}

每个查询、每个字段或每个索引都可以指定分析器。在创建索引时查找分析器的顺序：

* 在字段映射中定义的分析器。
* 在索引设置中名为 default 的分析器。
* 标准分析器。
* 在查询时，有更多的层次。
* 在全文查询中定义的分析器。
* 在字段映射中定义的搜索分析器。
* 在字段映射中定义的分析器。
* 在索引设置中名为 default_search 的分析器。
* 在索引设置中名为 default 的分析器。
* 标准分析器。

### 映射

* 字符串数据类型

- 全文本：可以用于分词，不用于排序而且很少聚合，用于基于文本的相关性搜索。
- 关键字：不参与分词，通常用于过滤，排序以及聚合。

字符串的参数：


| 参数                   | 备注                                                                                                                                                                                                                                    |
| ---------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| analyzer               | 分词器可以被用于可分词的字符串型字段。<br />默认为默认的索引分词器，或者标准分词器。                                                                                                                                                    |
| boost                  | 字段级索引加权。接受浮点型数字，默认值是 1.0。<br />doc_values 定义字段是否应该以列跨度的方式存储在磁盘上，<br />以便用于排序，聚合或者脚本？接受 true 或 false 参数。<br />对于不可分词字段，默认值是 true。可分词字段不支持这个参数。 |
| fielddate              | 决定字段是否可以使用内存字段值进行排序，聚合或者在脚本中使用。<br />接受 disabled 或者 paged_bytes（默认）参数。<br />没有分析过的字段会优先使用文档值。                                                                                |
| ignore_above           | 不要索引或执行任何长于这个值的字符串。默认为 0（禁用）。                                                                                                                                                                                |
| include_in_all         | 决定字段是否应该被包含在_all 字段中。接受 true 或 false 参数。<br />如果索引被设置为 no 或者父对象字段设置 include_in_all 为 false，<br />参数默认值为 false；其它情况下，默认值为 true。                                               |
| index                  | 决定字段是否可以被用户搜索。<br />接受参数 analyzed（默认，视为全文字段），<br />not_analyzed（作为关键字字段）以及 no。                                                                                                                |
| index_options          | 定义存储在索引中，用于搜索和突出用途的信息。                                                                                                                                                                                            |
| norms                  | 计算查询得分的时候是否应该考虑字段长度。<br />默认依赖于索引设置： analyzed <br />字段默认{ "enabled": true, "loading": "lazy" }。<br />not_analyzed 字段默认{ "enabled": false }。                                                     |
| null_value             | 接受一个字符串值替换所有 null 值。默认为 null，意味着字段被作为缺失字段。<br />如果字段是可分词（analyzed）的，null_value 也会被分词。                                                                                                  |
| position_increment_gap | 定义字符串数组中应该插入的虚拟索引词的数量。<br />默认值为100，以一个较合理的值来阻止短语查询在跨字段匹配索引词的时候溢出。                                                                                                             |
| store                  | 决定字段值是否应该被存储以及从_source 字段分别获取。<br />接受参数 true 或 false（默认）。                                                                                                                                              |
| search_analyzer        | 指定搜索时用在可分词字段上的分词器。                                                                                                                                                                                                    |
| search_quote_analyzer  | 指定搜索短语时使用的分词器。                                                                                                                                                                                                            |
| similarity             | 指定使用的相似度评分算法，默认为 TF/IDF。                                                                                                                                                                                               |
| term_vector            | 定义一个可分词字段是否应该存储索引词向量。默认为 no。                                                                                                                                                                                   |

* 数字型数据类型


| 类型    | 备注                                                     |
| ------- | -------------------------------------------------------- |
| long    | 一个有符号的 64 位整数，最小值为 -2^63 ，最大值为 2^63-1 |
| integer | 一个有符号的 32 位整数，最小值为-2^31 ，最大值为 2^31-1  |
| short   | 一个有符号的 16 位整数，最小值为-32768，最大值为 32767。 |
| byte    | 一个有符号的 8 位整数，最小值为-128，最大值为 127。      |
| double  | 64 位双精度浮点数。                                      |
| float   | 32 位单精度浮点数。                                      |

数字的参数：


| 参数             | 备注                                                                                                                                                                                      |
| ---------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| coerce           | 试着将字符串型数据转换为整数型数字数据。                                                                                                                                                  |
| boost            | 字段级索引加权，接受浮点型数字参数，默认为 1.0。                                                                                                                                          |
| doc_values       | 定义字段是否应该以列跨度的方式存储在磁盘上，<br />以便用于排序，聚合或者脚本？接受 true（默认）或 false 参数。                                                                            |
| ignore_malformed | 如果是 true，畸形的数字会被忽略。<br />如果是 false（默认），畸形数字会抛出异常并丢弃整个文档。                                                                                           |
| include_in_all   | 决定字段是否应该被包含在_all 字段中。接受 true 或 false 参数。<br />如果索引被设置为 no 或者父对象字段设置 include_in_all 为 false，<br />参数默认值为 false；其他情况下，默认值为 true。 |
| index            | 决定字段是否可以被用户搜索。<br />接受参数 not_analyzed（默认）以及 no。 <br />null_value 接受与字段同类型的数字型值来代替 null 值。<br />默认是 null，意味着字段被作为缺失字段。         |
| precision_step   | 控制索引的额外索引词的数量来使范围查询更快速。<br />默认值取决于数字类型。                                                                                                                |
| store            | 决定字段值是否应该被存储以及从_source 字段分别获取。<br />接受参数 true或 false（默认）。                                                                                                 |

* 时间类型

默认值为 `strict_date_optional_time||epoch_millis`，`||` 表示多时间格式，会依次尝试。


| 参数           | 备注                                                                                                                                                                                            |
| -------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| boost          | 字段级索引加权，接受浮点型数字参数，默认为 1.0。                                                                                                                                                |
| doc_values     | 定义字段是否应该以列跨度的方式存储在磁盘上，<br />以便用于排序，聚合或者脚本？接受 true（默认）或 false 参数。                                                                                  |
| format         | 可解析的日期格式。<br />ignore_malformed 如果是 true，畸形的日期会被忽略。<br />如果是 false（默认），畸形日期会抛出异常并丢弃整个文档。                                                        |
| include_in_all | 决定字段是否应该被包含在_all 字段中。<br />接受 true 或 false 参数。<br />如果索引被设置为 no 或者父对象字段设置 include_in_all 为 false，<br />参数默认值为 false；其他情况下，默认值为 true。 |
| index          | 决定字段是否可以被用户搜索。<br />接受参数 not_analyzed（默认）以及 no。 <br />null_value 接受日期型值来代替 null 值。<br />默认是 null，意味着字段被作为缺失字段。                             |
| precision_step | 控制索引的额外索引词的数量来使范围查询更快速。默认值为 16。                                                                                                                                     |
| store          | 决定字段值是否应该被存储以及从_source 字段分别获取。<br />接受参数 true 或 false（默认）。                                                                                                      |

* 布尔类型

布尔型字段接受 true 或 false 值，也可以接受代表真或假的字符串和数字。
假值 false，“false”，“off”，“no”，“0”，“”（空字符串），0，0.0
真值 其他任何非假的值


| 参数       | 备注                                                                                                                                                                |
| ---------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| doc_values | 定义字段是否应该以列跨度的方式存储在磁盘上，<br />以便用于排序，聚合或者脚本？接受 true（默认）或 false 参数。                                                      |
| index      | 决定字段是否可以被用户搜索。<br />接受参数 not_analyzed（默认）以及 no。<br /> null_value 接受布尔型值来代替 null 值。<br />默认是 null，意味着字段被作为缺失字段。 |
| store      | 决定字段值是否应该被存储以及从_source字段分别获取。<br />接受参数true或false（默认）。                                                                              |

* 二进制数据类型

二进制数据类型接受 Base64 编码字符串的二进制值。字段不以默认方式存储而且不能被搜索。


| 参数       | 备注                                                                                                           |
| ---------- | -------------------------------------------------------------------------------------------------------------- |
| doc_values | 定义字段是否应该以列跨度的方式存储在磁盘上，<br />以便用于排序，聚合或者脚本？接受 true（默认）或 false 参数。 |
| store      | 决定字段值是否应该被存储以及从_source字段分别获取。<br />接受参数true或false（默认）。                         |

* 元字段


| 字段名        | 备注                                            |
| ------------- | ----------------------------------------------- |
| _index        | 文档所属的索引。                                |
| _uid          | 包含_type 和_id 的混合字段。                    |
| _type         | 文档的映射类型。                                |
| _id           | 文档的 ID                                       |
| _source       | 作为文档内容的原始 JSON。                       |
| _size _source | 元字段占用的字节数，通过 mapper-size 插件提供。 |
| _all          | 索引所有字段的值                                |
| _field_names  | 文档中所有包含非空值的字段。                    |
| _timestamp    | 关联文章的时间戳，可以手动指定或者自动生成。    |
| _ttl          | 定义文档被自动删除之前的存活时间。              |
| _parent       | 用于在映射类型之间创建父子关系。                |
| _routing      | 一个自定义的路由值，路由文档到一个特定的分片。  |
| _meta         | 应用特定的元字段。                              |

### 文档

元数据：

* _index：所属索引，名称必须为全部小写，不能以下划线开头，不能包含逗号。
* _type：所属类型，每个类型都有自己的映射，类型的映射告诉 ElasticSearch 如何索引。
* _id：一个字符串，与_index和_type组合时可以在 ElasticSearch 中唯一标识一个文档，_id 可以自定义，也可以由 ElasticSearch 生成。

索引文档：

```bash
# 指定 ID
PUT /<index>/<type>/<id>
{
  文档内容
}

# 自动生成ID
POST /<index>/<type>
{
  文档内容
}
```

检索文档：

```bash
# pretty参数，美化输出 响应内容包括 "found":true,如果找不到，则包括 "found":false,不管找到与否，状态码都是200
GET /<index>/<type>/<id>?pretty
# 输出部分文档
GET /<index>/<type>/<id>?_source=<field1>,<field2>
# 只请求_source
GET /<index>/<type>/<id>/_source
# 检测文档是否存在
curl -i -XHEAD http://localhost:9200/<index>/<type>/<id>
```

更新文档：和索引文档同一个操作

```bash
# 更新成功后，_version 会加1，还会有 "created":false 属性
# 在内部是将旧文档标记删除，并且不能访问，然后添加新文档，文档时不可变的，不能被更改只能被替换
PUT /<index>/<type>/<id>
{
  文档内容
}
# 更新文档时指定版本，版本匹配才能修改
PUT /<index>/<type>/<id>?version=<num>
{
  文档内容
}
# 指定外部版本，比如数据库中版本，这个版本不需要完全匹配，只要后来版本大于之前版本就可以修改
PUT /<index>/<type>/<id>?version=<num>&version_type=external
{
  文档内容
}
```

添加新文档，确保不是更新：

```bash
PUT /<index>/<type>/<id>?op_type=create
{
  文档内容
}
# 或
PUT /<index>/<type>/<id>/_create
{
  文档内容
}
```

删除文档：

```bash
DELETE /<index>/<type>/<id>
```

局部更新文档：更新请求接受一个局部文档参数doc，它会合并到现有文档中——存在的字段被覆盖，新字段被添加。

```bash
POST /<index>/<type>/<id>/_update
{
  "doc":{
     文档内容
   }
}
```

使用groovy脚本更新：

```bash
# ctx._source 表示 _source 的变量
# ctx.op 表示操作的变量，比如 delete 表示删除，none 表示什么都不做
POST /<index>/<type>/<id>/_update?retry_on_conflict=5  # 表示版本冲突时重试的次数
{
  "script":"groovy脚本",
  "params": {
     定义脚本变量
  },
  "upsert"：{
     如果不存在则新增
  }
}
```

检索多个文档：

```bash
GET /_mget
{
  "docs": [
     {
        文档1 条件
     },
     {
        文档2 条件
     },
   ] 
}
或者
GET /<index>/<type>/_mget
{
  "docs": [
     {
        文档1 条件
     },
     {
        文档2 条件
     },
   ] 
}
```

批量操作bulk：

```bash
# 不是原子操作，各操作互不干扰
# 批量请求会先加载到请求节点的内存，所以请求越大，给其他请求可用内存越小。
POST /_bulk
{"create":{ 元数据 }}   # 当文档不存在时创建
{ 前一行操作的文档数据 }
{"update":{ 元数据 }}   # 局部更新文档
{ 前一行操作的文档数据 }
{"delete":{ 元数据 }}   # 删除一个文档
{ 前一行操作的文档数据 }
{"index":{ 元数据 }}   # 索引文档 或 更新文档
{ 前一行操作的文档数据 }
或
POST /<index>/<type>/_bulk
{"create":{ 元数据 }}   # 当文档不存在时创建
{ 前一行操作的文档数据 }
{"update":{ 元数据 }}   # 局部更新文档
{ 前一行操作的文档数据 }
{"delete":{ 元数据 }}   # 删除一个文档
{ 前一行操作的文档数据 }
{"index":{ 元数据 }}   # 索引文档 或 更新文档
{ 前一行操作的文档数据 }
```

由于批量操作中文档可能属于不同的主分片，意味着需要转发到对应的分片，为了减少解析数据，使用换行符识别数据行，减少内存消耗。

#### 路由文档到分片

当索引一个文档时，文档被存储在单独一个主分片上，路由分片的算法为 hash(routing) % number_of_primary_shards。

其中 routing 是一个任意字符串，默认值是 _id，也可以自定义，number_of_primary_shards 是主分片的数量。

#### 主分片和复制分片的交互

每个节点都知道任意文档所在的节点，可以将请求转发到需要的节点，所以集群中任意节点都可以处理请求。

##### 写操作

新建、索引、删除都是写操作，它们必须在主分片上成功完成才能复制到相关的复制分片上。

1. 客户端发送请求到任意节点。
2. 节点使用_id确定文档分片，转发请求到具有该主分片的目标节点。
3. 目标节点在主分片上执行请求，如果成功，转发请求到主分片的的复制节点上，当所有复制节点响应成功，目标节点响应最初请求节点，请求节点再响应客户端。

replication：复制默认值为 sync，表示主分片需要等复制分片成功响应才返回，当设置为 async 时，主分片不会等复制分片响应，但依旧会转发请求。一般不使用，因为在不等待其他分片就绪就请求，可能导致请求过多而过载。

consistency：默认主分片在尝试写入时需要规定数量或过半的分片可用，计算方法为：( 1 个 primary + 复制分片的数量(不是现在活动的分片而是索引中的配置) )/2 + 1 。

新索引默认只有1个复制分片，表示需要2个活动分片，这个默认设置将阻止我们在单一节点集群中操作，可以将索引 number_of_replicas 设置大于1来改变。

timeout：当副本不足时，默认等待1分钟。

##### 检索文档

1. 客户端发送请求到任意节点。
2. 节点使用_id确定文档分片，然后请求具有该文档分片的节点，为了负责均衡，请求节点会为每个请求选择不同的分片即循环所有分片副本。
3. 目标节点返回数据给请求节点，然后请求节点返回给客户端。

##### 局部更新文档

1. 客户端发送请求到任意节点。
2. 转发请求到主分片所在节点。
3. 目标节点从主分片检索出文档，修改_source字段的字段，然后在主分片重建索引，如果有其他进程修改文档，以 retry_on_conflict 设置的次数重试，都为成功则放弃。
4. 如果 目标节点 更新文档成功，转发新文档到复制节点重建索引，当所有复制节点报告成功，目标节点返回成功到请求节点，然后请求节点返回给客户端。

##### 多文档操作

1. 客户端发送请求到任意节点。
2. 请求节点为每个分片构建一个多条数据请求，然后转发这些请求，当所有回复被接收，请求节点返回给客户端。

## 搜索API

### 空搜索

`GET /_search`返回集群索引中的所有文档。

返回结果：

* hits：返回匹配到的前10条数据。
* took：请求花费毫秒。
* shards：返回查询的分片数total，查询成功的分片数successful，查询失败的分片数failed。

`GET /_search?timeout=10ms`返回在请求超时前收集到的结果，后台并不会停止查询，只是不再返回结果。

### 多索引、多类别

![1008.png](./assets/1008.png)

### 分页

![1009.png](./assets/1009.png)

### 简易搜索

`GET /_all/tweet1/_search?q=tweet:elasticsearch`：搜索类型为 tweet1 并在 tweet 字段包含 elasticsearch 字符的文档，可添加+前缀表示条件必须满足，-前缀表示必须不满足，例如 `+name:john +tweet:mary`

`GET /_search?q=mary`：搜索包含 mary 的所有结果。

### 查询映射

`GET /gb/_mapping/tweet`

### 结构化查询

#### 查询

match\_all 可以查询到所有文档，是没有查询条件下的默认语句。

```json
{
     "match_all": {}
}
```

match 查询是一个标准查询，不管你需要全文本查询还是精确查询基本上都要用到它。

使用 match 查询一个全文本字段，它会在真正查询之前用分析器先分析 match 一下查询字符：

```json
{
    "match": {
        "tweet": "About Search"
    }
}
```

使用 match 指定了一个确切值，在遇到数字，日期，布尔值或者 not\_analyzed 的字符串时，它将为你搜索你给定的值：

```json
{ "match": { "age": 26 }}
{ "match": { "date": "2014-09-01" }}
{ "match": { "public": true }}
{ "match": { "tag": "full_text" }}
```

bool 查询 合并多个查询子句，要计算每一个查询子句的 \_score （相关性分值）。

must :: 查询指定文档一定要被包含。

must\_not :: 查询指定文档一定不要被包含。

should :: 查询指定文档，有则可以为文档相关性加分。

```json
{
    "bool": {
      "must": { "match": { "title": "how to make millions" }},
      "must_not": { "match": { "tag": "spam" }},
      "should": [
          { "match": { "tag": "starred" }},
          { "range": { "date": { "gte": "2014-01-01" }}}
      ]
    }
}
```

#### 过滤

term 主要用于精确匹配哪些值。

```json
{ "term": { "age": 26 }}
{ "term": { "date": "2014-09-01" }}
{ "term": { "public": true }}
{ "term": { "tag": "full_text" }}
```

terms 允许指定多个匹配条件。 如果某个字段指定了多个值，文档则需要一起去做匹配。

```json
{
    "terms": {
        "tag": [ "search", "full_text", "nosql" ]
    }
}
```

range 过滤允许我们按照指定范围查找。

```json
{
    "range": {
        "age": {
            "gte": 20,
            "lt": 30
        }
    }
}
```

exists 和 missing 过滤可以用于查找文档中是否包含指定字段或没有某个字段。

```json
{
    "exists": {
        "field": "title"
    }
}
```

bool 过滤可以用来合并多个过滤条件查询结果的布尔逻辑，它包含一下操作符：

must :: 多个查询条件的完全匹配,相当于 and 。

must\_not :: 多个查询条件的相反匹配，相当于 not 。

should :: 至少有一个查询条件匹配, 相当于 or 。

```json
{
    "bool": {
        "must": { "match": { "tweet": "elasticsearch" }},
        "must_not": { "match": { "name": "mary" }},
        "should": { "match": { "tweet": "full text" }}
    }
}
```

#### 带过滤的查询语句

```bash
GET /_search
{
  "query": {
    "filtered": {
      "query": { "match": { "email": "business opportunity" }},
      "filter": { "term": { "folder": "inbox" }}
    }
  }
}
```

#### 排序

```bash
GET /_search
{
  "query" : {
    "filtered" : {
        "query": { "match": { "tweet": "manage text search" }},
        "filter" : { "term" : { "user_id" : 2 }}
    }
  },
  "sort": [
      { "date": { "order": "desc" }},
      { "_score": { "order": "desc" }}
  ]
}
```
