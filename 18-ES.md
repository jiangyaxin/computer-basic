## 概述

优点：

* 横向可扩展，扩大集群容易。
* 分片机制提供更好的分布性。
* 高可用，提供复制机制。
* 使用简单。

全文搜索是指通过扫描文章中的每一个词，对每个词建立一个索引，指明该词在文章中出现的次数和位置。

倒排索引：对文档或者文档集合中的单词建立索引，用来储存这些单词在文档或者一组文档中出现的频度、位置。

术语：

* 索引词：一个能够被索引的精确词。
* 文本：一段普通的非结构化文字，通常文本会被分析成一个个索引词。
* 分析：将文本转换为索引词的过程，分析结果依赖于分词器。
* 集群：集群由一个或多个节点组成，对外提供服务。在所有节点中，一个集群由一个唯一的名称，默认为 ElasticSearch，不同的集群应当使用不同的名称，节点是通过集群名称加入集群的。
* 节点：一个逻辑上独立的服务，节点也有唯一的名字，在网络中集群通过名字来管理和通信，当网络中没有集群运行时，只要启动任何一个节点，就会生成一个只有一个节点的集群。
* 路由：储存文档时，会储存在唯一的主分片中，具体哪个分片时通过散列值进行选择，默认情况下，散列值由文档ID生成，如果文档存在一个父文档，则由父文档ID生成。
* 分片：单个Lucene(全文搜索引擎工具包)实例，文档储存在分片中，分片分配在集群的节点，当集群扩容或缩小时，ElasticSearch 将自动在节点间迁移分片，以使集群保持平衡。
* 主分片：储存文档时，系统会首先储存在主分片中，然后会复制到不同的副本，默认情况一个索引有5个分片，分片一旦建立，数量就不能修改。
* 副本分片：每个分片有零个或多个副本，副本是主分片的复制，有两个目的：

  1. 增加高可用性，允许水平分割扩展数据：当主分片失败时，可用从副本中选择一个作为主分片。
  2. 提高性能，允许分配和并行操作提高吞吐量：可以通过主分片或者副本分片进行查询。默认情况下，一个主分片配有一个副本，但副本的数量可以在后面动态地配置增加。副本分片必须部署在不同的节点，不能部署在和主分片相同的节点。

  默认情况下，每个索引分配5个分片和一个副本，意味着集群节点至少要有两个，将拥有5个主分片、5个副本分片。
* 索引：名词表示 具有相同结构的文档集合，对应关系型数据库的 Database，动词表示把文档储存到索引(名词)中，对应关系型数据库的 Insert 操作。
* 类型：在索引中可以定义一个或多个类型，类型是索引的逻辑分区，对应关系型数据库的 Table。
* 文档：储存在 ElasticSearch 中的一个JSON格式的字符串，代表一行数据，对应关系型数据库的 Row。每个储存在索引中的文档都有一个类型和一个ID，每个文档都是一个JSON对象，储存了零个或多个字段，原始的JSON文档被储存在 _source 的字段中，当搜索文档时默认返回的就是这个字段。
* 映射：映射像关系数据库中的表结构，每个类型都有一个映射。
* 字段：文档中包含零个或多个字段，对应关系型数据库的 Column。
* 来源字段：默认情况下，原文档储存在 _source 字段。
* 主键：如果存库时没有，会自动生成一个，文档的 index/type/id 必须唯一。

分布式特性：

* 将文档分区到不同的容器或者分片(shards)中，它们可以存在于一个或多个节点中。
* 将分片均匀的分配到各个节点，对索引和搜索做负载均衡。
* 冗余每一个分片，防止硬件故障造成的数据丢失。
* 将集群中任意一个节点上的请求路由到相应数据所在的节点。
* 无论是增加节点，还是移除节点，分片都可以做到无缝的扩展和迁移。

## 常用配置

```yaml
# 集群名称，节点通过该值加入集群
cluster.name
# 节点名称
node.name
# 机架名称
node.rack
# 索引储存位置
path.data
# 日志储存位置
path.logs
# 内存分配模式，为true时先获取配置大小内存，再加入集群，并且禁止内存和磁盘交换
bootstrap.mlockall
# 绑定ip地址，默认127.0.0.1
network.host
# http端口
http.port
```

## 数据

### curl

格式：`curl <options> <url>`

options：

* -o：`-o <file-name>` , 将请求保存为文件。
* -O：用原文件名保存。
* -C -：断点继续下载。
* -i：打印响应头。
* -b：传递cookie。
* -H：指定header，例如`-H 'content-type: application/json'`
* -X：指定请求方法，例如`-X POST`
* -d：指定请求数据。
* -F：向服务器上传二进制文件，例如`-F 'file=@photo.png;type=image/png'`
* -k：跳过ssl检测。
* -L：跟随重定向。
* -s：不输出错误信息和进度信息。
* -S：只输出错误信息。
* -u：设置用户名密码。

### 文档

元数据：

* _index：所属索引，名称必须为全部小写，不能以下划线开头，不能包含逗号。
* _type：所属类型，每个类型都有自己的映射，类型的映射告诉 ElasticSearch 如何索引。
* _id：一个字符串，与_index和_type组合时可以在 ElasticSearch 中唯一标识一个文档，_id 可以自定义，也可以由 ElasticSearch 生成。

索引文档：

```bash
# 指定 ID
PUT /<index>/<type>/<id>
{
  文档内容
}

# 自动生成ID
POST /<index>/<type>
{
  文档内容
}
```

检索文档：

```bash
# pretty参数，美化输出 响应内容包括 "found":true,如果找不到，则包括 "found":false,不管找到与否，状态码都是200
GET /<index>/<type>/<id>?pretty
# 输出部分文档
GET /<index>/<type>/<id>?_source=<field1>,<field2>
# 只请求_source
GET /<index>/<type>/<id>/_source
# 检测文档是否存在
curl -i -XHEAD http://localhost:9200/<index>/<type>/<id>
```

更新文档：和索引文档同一个操作

```bash
# 更新成功后，_version 会加1，还会有 "created":false 属性
# 在内部是将旧文档标记删除，并且不能访问，然后添加新文档，文档时不可变的，不能被更改只能被替换
PUT /<index>/<type>/<id>
{
  文档内容
}
# 更新文档时指定版本，版本匹配才能修改
PUT /<index>/<type>/<id>?version=<num>
{
  文档内容
}
# 指定外部版本，比如数据库中版本，这个版本不需要完全匹配，只要后来版本大于之前版本就可以修改
PUT /<index>/<type>/<id>?version=<num>&version_type=external
{
  文档内容
}
```

添加新文档，确保不是更新：

```bash
PUT /<index>/<type>/<id>?op_type=create
{
  文档内容
}
# 或
PUT /<index>/<type>/<id>/_create
{
  文档内容
}
```

删除文档：

```bash
DELETE /<index>/<type>/<id>
```

局部更新文档：更新请求接受一个局部文档参数doc，它会合并到现有文档中——存在的字段被覆盖，新字段被添加。

```bash
POST /<index>/<type>/<id>/_update
{
  "doc":{
     文档内容
   }
}
```

使用groovy脚本更新：

```bash
# ctx._source 表示 _source 的变量
# ctx.op 表示操作的变量，比如 delete 表示删除，none 表示什么都不做
POST /<index>/<type>/<id>/_update?retry_on_conflict=5  # 表示版本冲突时重试的次数
{
  "script":"groovy脚本",
  "params": {
     定义脚本变量
  },
  "upsert"：{
     如果不存在则新增
  }
}
```

检索多个文档：

```bash
GET /_mget
{
  "docs": [
     {
        文档1 条件
     },
     {
        文档2 条件
     },
   ] 
}
或者
GET /<index>/<type>/_mget
{
  "docs": [
     {
        文档1 条件
     },
     {
        文档2 条件
     },
   ] 
}
```

批量操作bulk：

```bash
# 不是原子操作，各操作互不干扰
# 批量请求会先加载到请求节点的内存，所以请求越大，给其他请求可用内存越小。
POST /_bulk
{"create":{ 元数据 }}   # 当文档不存在时创建
{ 前一行操作的文档数据 }
{"update":{ 元数据 }}   # 局部更新文档
{ 前一行操作的文档数据 }
{"delete":{ 元数据 }}   # 删除一个文档
{ 前一行操作的文档数据 }
{"index":{ 元数据 }}   # 索引文档 或 更新文档
{ 前一行操作的文档数据 }
或
POST /<index>/<type>/_bulk
{"create":{ 元数据 }}   # 当文档不存在时创建
{ 前一行操作的文档数据 }
{"update":{ 元数据 }}   # 局部更新文档
{ 前一行操作的文档数据 }
{"delete":{ 元数据 }}   # 删除一个文档
{ 前一行操作的文档数据 }
{"index":{ 元数据 }}   # 索引文档 或 更新文档
{ 前一行操作的文档数据 }
```

由于批量操作中文档可能属于不同的主分片，意味着需要转发到对应的分片，为了减少解析数据，使用换行符识别数据行，减少内存消耗。

#### 路由文档到分片

当索引一个文档时，文档被存储在单独一个主分片上，路由分片的算法为 hash(routing) % number_of_primary_shards。

其中 routing 是一个任意字符串，默认值是 _id，也可以自定义，number_of_primary_shards 是主分片的数量。

#### 主分片和复制分片的交互

每个节点都知道任意文档所在的节点，可以将请求转发到需要的节点，所以集群中任意节点都可以处理请求。

##### 写操作

新建、索引、删除都是写操作，它们必须在主分片上成功完成才能复制到相关的复制分片上。

1. 客户端发送请求到任意节点。
2. 节点使用_id确定文档分片，转发请求到具有该主分片的目标节点。
3. 目标节点在主分片上执行请求，如果成功，转发请求到主分片的的复制节点上，当所有复制节点响应成功，目标节点响应最初请求节点，请求节点再响应客户端。

replication：复制默认值为 sync，表示主分片需要等复制分片成功响应才返回，当设置为 async 时，主分片不会等复制分片响应，但依旧会转发请求。一般不使用，因为在不等待其他分片就绪就请求，可能导致请求过多而过载。

consistency：默认主分片在尝试写入时需要规定数量或过半的分片可用，计算方法为：( 1 个 primary + 复制分片的数量(不是现在活动的分片而是索引中的配置) )/2 + 1 。

新索引默认只有1个复制分片，表示需要2个活动分片，这个默认设置将阻止我们在单一节点集群中操作，可以将索引 number_of_replicas 设置大于1来改变。

timeout：当副本不足时，默认等待1分钟。

##### 检索文档

1. 客户端发送请求到任意节点。
2. 节点使用_id确定文档分片，然后请求具有该文档分片的节点，为了负责均衡，请求节点会为每个请求选择不同的分片即循环所有分片副本。
3. 目标节点返回数据给请求节点，然后请求节点返回给客户端。

##### 局部更新文档

1. 客户端发送请求到任意节点。
2. 转发请求到主分片所在节点。
3. 目标节点从主分片检索出文档，修改_source字段的字段，然后在主分片重建索引，如果有其他进程修改文档，以 retry_on_conflict 设置的次数重试，都为成功则放弃。
4. 如果 目标节点 更新文档成功，转发新文档到复制节点重建索引，当所有复制节点报告成功，目标节点返回成功到请求节点，然后请求节点返回给客户端。

##### 多文档操作

1. 客户端发送请求到任意节点。
2. 请求节点为每个分片构建一个多条数据请求，然后转发这些请求，当所有回复被接收，请求节点返回给客户端。

## 搜索API

### 空搜索

`GET /_search`返回集群索引中的所有文档。

返回结果：

* hits：返回匹配到的前10条数据。
* took：请求花费毫秒。
* shards：返回查询的分片数total，查询成功的分片数successful，查询失败的分片数failed。

`GET /_search?timeout=10ms`返回在请求超时前收集到的结果，后台并不会停止查询，只是不再返回结果。

### 多索引、多类别

![1008.png](./assets/1008.png)

### 分页

![1009.png](./assets/1009.png)

### 简易搜索

`GET /_all/tweet1/_search?q=tweet:elasticsearch`：搜索类型为 tweet1 并在 tweet 字段包含 elasticsearch 字符的文档，可添加+前缀表示条件必须满足，-前缀表示必须不满足，例如 `+name:john +tweet:mary`

`GET /_search?q=mary`：搜索包含 mary 的所有结果。

### 查询映射

`GET /gb/_mapping/tweet`

### 结构化查询

#### 查询

match\_all 可以查询到所有文档，是没有查询条件下的默认语句。

```json
{
     "match_all": {}
}
```

match 查询是一个标准查询，不管你需要全文本查询还是精确查询基本上都要用到它。

使用 match 查询一个全文本字段，它会在真正查询之前用分析器先分析 match 一下查询字符：

```json
{
    "match": {
        "tweet": "About Search"
    }
}
```

使用 match 指定了一个确切值，在遇到数字，日期，布尔值或者 not\_analyzed 的字符串时，它将为你搜索你给定的值：

```json
{ "match": { "age": 26 }}
{ "match": { "date": "2014-09-01" }}
{ "match": { "public": true }}
{ "match": { "tag": "full_text" }}
```

bool 查询 合并多个查询子句，要计算每一个查询子句的 \_score （相关性分值）。

must :: 查询指定文档一定要被包含。

must\_not :: 查询指定文档一定不要被包含。

should :: 查询指定文档，有则可以为文档相关性加分。

```json
{
    "bool": {
      "must": { "match": { "title": "how to make millions" }},
      "must_not": { "match": { "tag": "spam" }},
      "should": [
          { "match": { "tag": "starred" }},
          { "range": { "date": { "gte": "2014-01-01" }}}
      ]
    }
}
```

#### 过滤

term 主要用于精确匹配哪些值。

```json
{ "term": { "age": 26 }}
{ "term": { "date": "2014-09-01" }}
{ "term": { "public": true }}
{ "term": { "tag": "full_text" }}
```

terms 允许指定多个匹配条件。 如果某个字段指定了多个值，文档则需要一起去做匹配。

```json
{
    "terms": {
        "tag": [ "search", "full_text", "nosql" ]
    }
}
```

range 过滤允许我们按照指定范围查找。

```json
{
    "range": {
        "age": {
            "gte": 20,
            "lt": 30
        }
    }
}
```

exists 和 missing 过滤可以用于查找文档中是否包含指定字段或没有某个字段。

```json
{
    "exists": {
        "field": "title"
    }
}
```

bool 过滤可以用来合并多个过滤条件查询结果的布尔逻辑，它包含一下操作符：

must :: 多个查询条件的完全匹配,相当于 and 。

must\_not :: 多个查询条件的相反匹配，相当于 not 。

should :: 至少有一个查询条件匹配, 相当于 or 。

```json
{
    "bool": {
        "must": { "match": { "tweet": "elasticsearch" }},
        "must_not": { "match": { "name": "mary" }},
        "should": { "match": { "tweet": "full text" }}
    }
}
```

#### 带过滤的查询语句

```json
GET /_search
{
  "query": {
    "filtered": {
      "query": { "match": { "email": "business opportunity" }},
      "filter": { "term": { "folder": "inbox" }}
    }
  }
}
```

#### 排序

```json
GET /_search
{
  "query" : {
    "filtered" : {
        "query": { "match": { "tweet": "manage text search" }},
        "filter" : { "term" : { "user_id" : 2 }}
    }
  },
  "sort": [
      { "date": { "order": "desc" }},
      { "_score": { "order": "desc" }}
  ]
}
```
